<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AAU Robot Dashboard</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    /* Overall Grid: 3 rows, 2 columns */
    #dashboard {
      display: grid;
      grid-template-rows: 25% 25% 50%;
      grid-template-columns: 50% 50%;
      width: 100vw;
      height: 100vh;
      min-width: 1920px;
      min-height: 1080px;
      box-sizing: border-box;
      overflow: hidden;
    }
    .panel {
      border: 1px solid #444;
      background: #2a2a2a;
      position: relative;
      display: flex;
      flex-direction: column;
      padding: 8px;
      box-sizing: border-box;
    }
    .panel-title {
      position: absolute;
      top: 8px;
      left: 8px;
      font-weight: bold;
      color: #fff;
      z-index: 2;
    }
    /* For video/image in each window */
    .media-container {
      width: 100%;
      height: 100%;
      display: flex;
      align-items: center;
      justify-content: center;
      overflow: hidden;
      position: relative;
    }
    /* Keep video/image scaled to container height */
    .media-content {
      max-height: 100%;
      max-width: 100%;
      object-fit: contain;
      display: block;
    }
    #llmConsole{
      font-size: 2em;          /* twice the original size  */
      line-height: 1.4;
      white-space: pre-wrap;   /* keep spaces & wrap long lines */
      word-break: break-word;
    }
    /* Overlay for image mode if no image is chosen */
    #uploadButton {
      position: absolute;
      top: 0; left: 0;
      width: 100%; height: 100%;
      display: none;
      background: rgba(0,0,0,0.5);
      color: #4af;
      font-size: 24px;
      align-items: center;
      justify-content: center;
      cursor: pointer;
      z-index: 4;
    }
    #fileUploadInput {
      display: none;
    }
    .console-area {
      background: #111;
      border: 1px solid #4af;
      font-family: monospace;
      padding: 4px;
      overflow-y: auto;
      flex: 1;
    }
    .neon-btn {
      background-color: #222;
      color: #4af;
      border: 1px solid #4af;
      transition: all 0.2s ease-in-out;
    }
    .neon-btn:hover {
      background-color: #4af;
      color: #111;
      box-shadow: 0 0 8px #4af;
    }
    select {
      background-color: #2a2a2a;
      color: #4af;
      border: 1px solid #4af;
      padding: 4px;
    }
  </style>
</head>
<body class="bg-gray-900 text-green-300">

<div id="dashboard">
  <!-- Row1, Col1: Side Camera (Window1) -->
  <div class="panel" style="grid-row:1; grid-column:1;">
    <div class="panel-title">Side Camera (Window1)</div>
    <!-- "camera" or "image" -->
    <select id="sideCamModeSelect" style="position:absolute; top:8px; right:8px; z-index:5;">
      <option value="camera">SideCam</option>
      <option value="image">Image</option>
    </select>
    <div id="sideCamContainer" class="media-container">
      <!-- If "camera", show a live video feed -->
      <video id="sideVideo" class="media-content" autoplay muted playsinline></video>
      <!-- If "image", show an uploaded image -->
      <img id="sideImage" class="media-content" src="" alt="UploadedImage" style="display:none;">
      <!-- Overlay for uploading an image if none is chosen yet -->
      <div id="uploadButton">Click to upload or drag &amp; drop</div>
      <input type="file" id="fileUploadInput" accept="image/*">
    </div>
  </div>

  <!-- Row1, Col2: Model Selection (Window5) -->
  <div class="panel" style="grid-row:1; grid-column:2; justify-content:center; align-items:center;">
    <div class="panel-title">Model Selection (Window5)</div>
    <div style="margin-top:2rem; display:flex; flex-direction:column; gap:1rem;">
      <div>
        <label>VLM:</label>
        <select id="vlmSelect">
          <option>OpenVLM_1</option>
          <option>OpenVLM_2</option>
          <option>OpenVLM_3</option>
        </select>
      </div>
      <div>
        <label>LLM:</label>
        <select id="llmSelect">
          <option>ChatGPT</option>
          <option>Llama</option>
          <option>Claude</option>
        </select>
      </div>
    </div>
  </div>

  <!-- Row2, Col1: Window2 (Seg) + Window3 (Depth) side by side -->
  <div class="panel" style="grid-row:2; grid-column:1; display:flex; flex-direction:row; padding:0;">
    <!-- Window2: Seg -->
    <div id="segContainer" class="media-container" style="flex:1; border-right:1px solid #333;">
      <div class="panel-title">Seg (Window2)</div>
      <video id="segVideo" class="media-content" autoplay muted playsinline></video>
      <img id="segImg" class="media-content" src="https://via.placeholder.com/320x180?text=Seg" alt="SegOutput" style="display:none;">
      <select id="segMode" style="position:absolute; top:8px; right:8px; z-index:5;">
        <option value="off">Off</option>
        <option value="seg">Window 1 Seg</option>
        <option value="realsense_seg">RealSense RGB</option>
      </select>
    </div>

    <!-- Window3: Depth -->
    <div id="depthContainer" class="media-container" style="flex:1;">
      <div class="panel-title">Depth (Window3)</div>
      <img id="depthImg" class="media-content" src="https://via.placeholder.com/320x180?text=Depth" alt="DepthOutput">
      <select id="depthMode" style="position:absolute; top:8px; right:8px; z-index:5;"></select>
    </div>
  </div>

  <!-- Row2, Col2: Robot Control (Window6) -->
  <div class="panel" style="grid-row:2; grid-column:2; justify-content:center; align-items:center;">
    <div class="panel-title">Robot Control (Window6)</div>
    <div style="margin-top:2rem; display:flex; gap:1rem;">
      <button class="neon-btn px-3 py-1" onclick="sendChat('move forward')">Forward</button>
      <button class="neon-btn px-3 py-1" onclick="sendChat('2 to the left')">Left x2</button>
      <button class="neon-btn px-3 py-1" onclick="sendChat('turn right')">Right</button>
    </div>
  </div>

<!-- Row3, Col1: Chat (Window4) - Modified -->
<div class="panel" style="grid-row:3; grid-column:1;">
  <div class="panel-title">Chat (Window4)</div>
  
  <!-- Welcome/Instructions Area (top 20%) -->
  <div style="height:20%; margin-top:30px; background:#0a0a0a; border:1px solid #4af; padding:8px; border-radius:4px; overflow-y:auto;">
    <div style="color:#4af; font-weight:bold; margin-bottom:4px;">🤖 AAU Robot Assistant</div>
    <div style="font-size:0.9em; line-height:1.3; color:#ccc;">
      <strong>Welcome!</strong> I can help you with:<br>
      • <strong>Pick objects:</strong> "Pick the red cup on the left"<br>
      • <strong>Place objects:</strong> "Place it in the dishwasher"<br>
      • <strong>Multi-step:</strong> "Pick the cup and place it on the table"<br>
      • <strong>Chat & ask questions</strong> about what I can see<br>
      <em style="color:#4af;">💡 Tip: Be specific about objects and locations!</em>
    </div>
  </div>
  
  <!-- Chat Messages Area (remaining 80%) -->
  <div id="chatMessages" style="flex:1; height:calc(80% - 40px); overflow-y:auto; background:#111; border:1px solid #666; padding:4px; margin-top:8px;"></div>
  
  <div style="margin-top:8px; display:flex;">
    <input type="text" id="chatInput" class="bg-gray-800 text-green-300 border border-green-500 px-2 py-1 flex-1" placeholder="Type command...">
    <button id="chatSendBtn" class="neon-btn px-3 py-1" style="margin-left:8px;">Send</button>
  </div>
</div>

  <!-- Row3, Col2: LLM Reasoning (Window7) -->
  <div class="panel" style="grid-row:3; grid-column:2; display:flex; flex-direction:column;">
    <div class="panel-title">LLM Reasoning (Window7)</div>
    <div id="llmConsole" class="console-area" style="margin-top:30px; font-size:2em; line-height:1.4;"></div>
  </div>
</div>

<script>
  /****************************************************
   * ELEMENT REFS
   ****************************************************/
  const sideCamModeSelect = document.getElementById("sideCamModeSelect");
  const sideVideo         = document.getElementById("sideVideo");
  const sideImage         = document.getElementById("sideImage");
  const uploadButton      = document.getElementById("uploadButton");
  const fileUploadInput   = document.getElementById("fileUploadInput");
  const sideCamContainer  = document.getElementById("sideCamContainer");
  
  const segMode      = document.getElementById("segMode");
  const segVideo     = document.getElementById("segVideo");
  const segImg       = document.getElementById("segImg");
  const segContainer = document.getElementById("segContainer");
  
  const depthMode = document.getElementById("depthMode");
  const depthImg  = document.getElementById("depthImg");
  
  const chatMessages = document.getElementById("chatMessages");
  const chatInput    = document.getElementById("chatInput");
  const chatSendBtn  = document.getElementById("chatSendBtn");
  
  const llmConsole = document.getElementById("llmConsole");
  
  /****************************************************
   * STATE
   ****************************************************/
  let localStream        = null;
  let uploadedImageData  = "";
  let segFrozen          = false;
  let isSegmenting       = false;
  let realsenseSegTimer  = null;
  let depthTimer         = null;
  
  /****************************************************
   * PAGE LOAD
   ****************************************************/
  window.addEventListener("DOMContentLoaded", async () => {
    // fetch camera info for depth dropdown
    try {
      const res = await fetch("/camera_info");
      const info = await res.json();
      window.realsenseAvailable = info.realsense_available;
    } catch {
      window.realsenseAvailable = false;
    }
    updateDepthDropdown();
    sideCamModeSelect.dispatchEvent(new Event("change"));
  });
  
  /****************************************************
   * SIDE CAMERA (Window1)
   ****************************************************/
  sideCamModeSelect.addEventListener("change", () => {
    const mode = sideCamModeSelect.value;
    if (mode === "camera") {
      startSideCam();
      sideVideo.style.display = "block";
      sideImage.style.display = "none";
      uploadButton.style.display = "none";
    } else {
      stopSideCam();
      if (uploadedImageData) {
        sideImage.src = uploadedImageData;
        sideImage.style.display = "block";
        uploadButton.style.display = "none";
      } else {
        sideImage.style.display = "none";
        uploadButton.style.display = "flex";
      }
      sideVideo.style.display = "none";
    }
    updateDepthDropdown();
  });
  
  async function startSideCam() {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { width:1280, height:720, frameRate:20 },
        audio: false
      });
      localStream = stream;
      sideVideo.srcObject = stream;
      // mirror to Seg window if active
      if (segMode.value === "seg") {
        segVideo.srcObject = stream;
      }
    } catch (e) {
      console.error("startSideCam:", e);
    }
  }
  function stopSideCam() {
    if (localStream) {
      localStream.getTracks().forEach(t=>t.stop());
      localStream = null;
    }
    segVideo.srcObject = null;
  }
  
  uploadButton.addEventListener("click", () => fileUploadInput.click());
  fileUploadInput.addEventListener("change", evt => {
    if (!evt.target.files.length) return;
    const file = evt.target.files[0];
    const rdr = new FileReader();
    rdr.onload = () => {
      uploadedImageData = rdr.result;
      sideImage.src = uploadedImageData;
      sideImage.style.display = "block";
      uploadButton.style.display = "none";
      if (segMode.value==="seg" && !segFrozen) {
        segImg.src = uploadedImageData;
        segImg.style.display = "block";
        segVideo.style.display = "none";
      }
      if (depthMode.value==="image_depth") processImageDepth();
    };
    rdr.readAsDataURL(file);
  });
  
  /****************************************************
   * SEGMENTATION (Window2)
   ****************************************************/
  segMode.addEventListener("change", () => {
    segFrozen = false;
    clearInterval(realsenseSegTimer);
    if (segMode.value === "seg") {
      if (localStream && sideCamModeSelect.value==="camera") {
        segVideo.srcObject = localStream;
        segVideo.style.display = "block";
        segImg.style.display = "none";
      } else {
        segVideo.style.display = "none";
        segImg.style.display = "block";
        segImg.src = uploadedImageData || segImg.src;
      }
    }
    else if (segMode.value==="realsense_seg") {
      segVideo.style.display = "none";
      segImg.style.display = "block";
      realsenseSegTimer = setInterval(fetchRealsenseSeg, 250);
    }
    else {
      segVideo.style.display = "none";
      segImg.style.display = "none";
    }
  });
  
  async function fetchRealsenseSeg() {
    try {
      const resp = await fetch("/process_realsense_seg",{ method:"POST" });
      if (!resp.ok) throw "";
      const d = await resp.json();
      if (d.frame) segImg.src = "data:image/jpeg;base64,"+d.frame;
    } catch {}
  }
  
async function sendChatStream(customText){
  const userText = (customText || chatInput.value).trim();
  if (!userText) return;

  chatInput.value = "";
  addChatMessage("You", userText);
  llmConsole.innerHTML = "";

  try {
    // Try streaming first
    console.log("🔍 Attempting streaming request...");
    const success = await tryStreamingChat(userText);
    
    if (!success) {
      console.log("🔄 Streaming failed, trying non-streaming fallback...");
      await tryFallbackChat(userText);
    }
    
  } catch (error) {
    console.error("❌ Chat error:", error);
    addChatMessage("AAU Agent", `Error: ${error.message}. Please try again.`);
  }
}

async function tryStreamingChat(userText) {
  try {
    const resp = await fetch("/chat-stream", {
      method : "POST",
      headers: { "Content-Type":"application/json" },
      body   : JSON.stringify({ text: userText })
    });

    if (!resp.ok) {
      console.log(`❌ Streaming response not ok: ${resp.status}`);
      return false;
    }

    const reader = resp.body.getReader();
    const decoder = new TextDecoder();
    let completeResponse = "";
    let reasoning = "";
    let answer = "";

    while (true) {
      const {done, value} = await reader.read();
      if (done) break;

      const chunk = decoder.decode(value, {stream: true});
      completeResponse += chunk;
      
      // Process each event
      const events = chunk.split(/\n\n/);
      for (const event of events) {
        if (!event.trim()) continue;
        
        console.log("📥 Stream event:", event.substring(0, 100) + "...");
        
        if (event.startsWith("event: reasoning")) {
          const reasoningText = event.slice(event.indexOf("data:") + 5).trim();
          reasoning += reasoningText + " ";
          llmConsole.innerHTML = reasoning.replace(/\n/g, "<br>");
          llmConsole.scrollTop = llmConsole.scrollHeight;
        }
        else if (event.startsWith("event: answer")) {
          const answerText = event.slice(event.indexOf("data:") + 5).trim();
          answer += answerText;
        }
        else if (event.startsWith("data: ") && !event.includes("event:")) {
          // Direct data without event type
          answer += event.slice(6);
        }
      }
    }

    console.log("🔍 Streaming complete. Full answer:", answer);
    
    if (answer.trim()) {
      answer = answer.replace(/\[DONE\]$/i, "").trim();
      await processLLMResponse(answer);
      return true;
    } else {
      console.log("❌ No answer received from streaming");
      return false;
    }
    
  } catch (error) {
    console.error("❌ Streaming error:", error);
    return false;
  }
}

async function tryFallbackChat(userText) {
  try {
    addChatMessage("AAU Agent", "Processing your request...");
    
    const resp = await fetch("/chat", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ prompt: userText })
    });

    if (!resp.ok) {
      throw new Error(`Server error: ${resp.status}`);
    }

    const data = await resp.json();
    console.log("🔍 Fallback response:", data);
    
    if (data.result) {
      await processLLMResponse(data.result);
    } else {
      addChatMessage("AAU Agent", "I didn't receive a valid response. Please try again.");
    }
    
  } catch (error) {
    console.error("❌ Fallback error:", error);
    addChatMessage("AAU Agent", `Fallback error: ${error.message}`);
  }
}

async function processLLMResponse(response) {
  console.log("🔍 Processing LLM response:", response);
  
  if (response.includes("[ACTION]")) {
    console.log("✅ ACTION block detected");
    await executeMultiStepActions(response);
  } else {
    console.log("💬 Regular chat response");
    addChatMessage("AAU Agent", response);
  }
}

async function executeMultiStepActions(actionBlock) {
  console.log("🔍 DEBUG: Raw action block:");
  console.log(actionBlock);
  
  try {
    // Extract [ACTION] block content
    const actionMatch = actionBlock.match(/\[ACTION\]\s*([\s\S]*?)(?:\n\n|$)/i);
    if (!actionMatch) {
      throw new Error("Could not find [ACTION] block in response");
    }
    
    const content = actionMatch[1].trim();
    console.log("🔍 DEBUG: Action content:");
    console.log(content);
    
    // Split into lines, but also handle if both are on the same line
    let lines = content.split('\n').map(line => line.trim()).filter(line => line);

    // If only one line and it contains both requests, split it
    if (lines.length === 1 && lines[0].includes("Action Request:")) {
      const idx = lines[0].indexOf("Action Request:");
      lines = [
        lines[0].slice(0, idx).trim(),
        lines[0].slice(idx).trim()
      ];
    }
    console.log("🔍 DEBUG: All lines:", lines);
    
    // Find the required lines
    let roboPointLine = null;
    let actionLine = null;
    
    for (const line of lines) {
      if (line.match(/^\s*RoboPoint\s+Request\s*:/i)) {
        roboPointLine = line;
        console.log("✅ Found RoboPoint line:", line);
      } else if (line.match(/^\s*Action\s+Request\s*:/i)) {
        actionLine = line;
        console.log("✅ Found Action line:", line);
      }
    }
    
    // Detailed error reporting
    if (!roboPointLine) {
      console.log("❌ Available lines:", lines);
      addChatMessage("AAU Agent", 
        `Error: Missing 'RoboPoint Request:' line. ` +
        `I received: ${lines.join(' | ')}. ` +
        `Please ask me again - I need both request and action lines.`
      );
      return;
    }
    
    if (!actionLine) {
      console.log("❌ Available lines:", lines);
      addChatMessage("AAU Agent", 
        `Error: Missing 'Action Request:' line. ` +
        `I found the RoboPoint line but need the Action line too. ` +
        `Available: ${lines.join(' | ')}. Please try asking again.`
      );
      return;
    }
    
    // Extract content after colons
    const roboPointContent = roboPointLine.split(':', 2)[1];
    const actionContent = actionLine.split(':', 2)[1];
    
    if (!roboPointContent || !actionContent) {
      addChatMessage("AAU Agent", "Error: Could not extract content from request/action lines");
      return;
    }
    
    // Parse the semicolon-separated values
    const objects = roboPointContent.split(';').map(s => s.trim()).filter(s => s);
    const actions = actionContent.split(';').map(s => s.trim()).filter(s => s);
    
    console.log("🔍 DEBUG: Parsed objects:", objects);
    console.log("🔍 DEBUG: Parsed actions:", actions);
    
    if (objects.length !== actions.length) {
      addChatMessage("AAU Agent", 
        `Error: Mismatch between objects (${objects.length}) and actions (${actions.length}). ` +
        `Objects: [${objects.join(', ')}] Actions: [${actions.join(', ')}]`
      );
      return;
    }
    
    if (objects.length === 0) {
      addChatMessage("AAU Agent", "Error: No valid commands found in the action block");
      return;
    }
    
    // Success - start processing
    addChatMessage("AAU Agent", `✅ Found ${objects.length} command(s). Starting execution...`);
    
    // Capture frame
    let frameB64 = "";
    try {
      frameB64 = await captureSegFrame();
      freezeSegWindow(frameB64);
    } catch(e) { 
      console.warn("No seg frame:", e);
      addChatMessage("AAU Agent", "Warning: Could not capture camera frame. Continuing anyway...");
    }

    // Execute each command
    for (let i = 0; i < objects.length; i++) {
      const object = objects[i];
      const action = actions[i];

      addChatMessage("AAU Agent", `🔄 Step ${i+1}: Finding "${object}"...`);

      try {
        const result = await executeRoboPointCommand(object, action, frameB64);

        if (result.seg_frame) {
          segImg.src = "data:image/jpeg;base64," + result.seg_frame;
        }

        // Show location for both pick and place
        if (result.object_info && result.object_info.center_xyz_m) {
          const info = result.object_info;
          addChatMessage("AAU Agent", 
            `✅ Step ${i+1}: Successfully found "${object}"! Location: ${info.center_xyz_m.map(v=>v.toFixed(3)).join(', ')} m, Distance: ${info.distance_m.toFixed(3)} m, Size: ${(info.width_m*100).toFixed(1)}×${(info.height_m*100).toFixed(1)} cm`
          );
        } else {
          addChatMessage("AAU Agent", `✅ Step ${i+1}: Successfully found "${object}"`);
        }

        // Pause between steps
        if (i < objects.length - 1) {
          await new Promise(resolve => setTimeout(resolve, 800));
        }

      } catch (error) {
        console.error(`❌ Step ${i+1} failed:`, error);
        addChatMessage("AAU Agent", `❌ Step ${i+1} Failed: ${error.message}`);
        break;
      }
    }
    
    addChatMessage("AAU Agent", `🎉 Completed ${objects.length} action(s)!`);
    
  } catch (error) {
    console.error("❌ Action parsing error:", error);
    addChatMessage("AAU Agent", `Action parsing error: ${error.message}`);
  }
}

async function executeRoboPointCommand(objectDescription, action, frameB64) {
  const singleActionBlock = `[ACTION]\nRoboPoint Request: ${objectDescription}\nAction Request: ${action}`;
  
  console.log("📤 Sending to RoboPoint:", singleActionBlock);
  
  const resp = await fetch("/exec_action", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({
      action_block: singleActionBlock,
      seg_frame: frameB64
    })
  });

  if (!resp.ok) {
    const errorText = await resp.text();
    throw new Error(`Server error ${resp.status}: ${errorText}`);
  }

  const result = await resp.json();
  console.log("📥 RoboPoint result:", result);
  
  if (result.error) {
    throw new Error(result.error);
  }
  
  return result;
}

// Freeze the Seg window — no more frames will arrive until we unfreeze
function freezeSegWindow(base64Frame) {
  segFrozen    = true;
  isSegmenting = true;
  clearInterval(realsenseSegTimer);

  // disable camera track & pause
  if (segMode.value === "seg" && localStream) {
    localStream.getVideoTracks().forEach(t => t.enabled = false);
    segVideo.pause();
  }

  // swap to your frozen JPEG
  segImg.src            = "data:image/jpeg;base64," + base64Frame;
  segVideo.style.display = "none";
  segImg.style.display   = "block";
}

// Unfreeze & resume your live feed
function unfreezeSegWindow() {
  segFrozen = false;
  fetch("/reset_seg", { method:"POST" }).catch();

  if (segMode.value === "seg" && localStream) {
    // re-enable track and replay
    localStream.getVideoTracks().forEach(t => t.enabled = true);
    segVideo.srcObject = localStream;
    segVideo.play();
    segVideo.style.display = "block";
    segImg.style.display   = "none";
  }
  else if (segMode.value === "realsense_seg") {
    realsenseSegTimer = setInterval(fetchRealsenseSeg, 250);
  }
}


segContainer.addEventListener("click", async ev => {
  if (!["seg","realsense_seg"].includes(segMode.value) || isSegmenting) return;

  // — FIRST CLICK: freeze and segment —
  if (!segFrozen) {
    try {
      const frameB64 = await captureSegFrame();
      freezeSegWindow(frameB64);

      // translate click → normalized image coords
      const rr = segImg.getBoundingClientRect();
      const nx = (ev.clientX - rr.left) / rr.width;
      const ny = (ev.clientY - rr.top)  / rr.height;

      const resp = await fetch("/process_seg", {
        method:  "POST",
        headers: { "Content-Type":"application/json" },
        body:    JSON.stringify({ frame: frameB64, clicked_x: nx, clicked_y: ny })
      });
      if (resp.ok) {
        const dd = await resp.json();
        if (dd.object_info) {
          addChatMessage(
            "AAU Agent",
            `Center: ${dd.object_info.center_xyz_m.map(v=>v.toFixed(3)).join(', ')} m; ` +
            `distance ${dd.object_info.distance_m.toFixed(3)} m; ` +
            `W×H ${(dd.object_info.width_m*100).toFixed(1)}×${(dd.object_info.height_m*100).toFixed(1)} cm`
          );
        }
        // update overlay on your frozen image
        segImg.src = "data:image/jpeg;base64," + dd.frame;
      }
    } catch(e) {
      console.error("Seg error:", e);
    } finally {
      isSegmenting = false;
    }
  }
  // — SECOND CLICK: unfreeze —
  else {
    unfreezeSegWindow();
  }
});

  /****************************************************
   * DEPTH (Window3)
   ****************************************************/
  function updateDepthDropdown(){
    if (sideCamModeSelect.value==="camera"){
      let opts = `
        <option value="off">Off</option>
        <option value="sidecam_depth">SideCam DepthAnything</option>
        <option value="other">Other (Inverse)</option>
      `;
      if (window.realsenseAvailable){
        opts+=`
          <option value="realsense_rgb_anything">RealSense RGB+DepthAnything</option>
          <option value="realsense_depth">RealSense Depth</option>
        `;
      }
      depthMode.innerHTML = opts;
    } else {
      depthMode.innerHTML = `
        <option value="off">Off</option>
        <option value="image_depth">Image Depth Anything</option>
      `;
    }
  }
  
  depthMode.addEventListener("change", () => {
    clearInterval(depthTimer);
    depthImg.src="https://via.placeholder.com/320x180?text=Depth";
    const v=depthMode.value;
    if (v==="off"){
      fetch("/process_depth",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({camera_mode:"off"})});
    }
    else if (sideCamModeSelect.value==="camera"){
      depthTimer=setInterval(() => processDepth(v),500);
    }
    else{
      processImageDepth();
    }
  });
  
  async function processDepth(mode){
    try {
      let b64="";
      if (mode==="sidecam_depth"||mode==="other"){
        b64 = await captureSideFrame();
      }
      const r = await fetch("/process_depth",{
        method:"POST",
        headers:{"Content-Type":"application/json"},
        body:JSON.stringify({ camera_mode:mode, local_idx:0, frame:b64 })
      });
      const d = await r.json();
      if (d.frame) depthImg.src="data:image/jpeg;base64,"+d.frame;
    } catch(e){ console.error(e) }
  }
  
  async function processImageDepth(){
    try {
      const b64 = await captureSideFrame();
      const r = await fetch("/process_depth",{
        method:"POST",
        headers:{"Content-Type":"application/json"},
        body:JSON.stringify({ camera_mode:"image_depth", local_idx:0, frame:b64 })
      });
      const d = await r.json();
      if (d.frame) depthImg.src="data:image/jpeg;base64,"+d.frame;
    } catch(e){ console.error(e) }
  }
  
  /****************************************************
   * FRAME CAPTURE UTILS
   ****************************************************/
  function captureSideFrame(){
    return new Promise((res,rej)=>{
      if (sideCamModeSelect.value==="camera" && localStream){
        const c=document.createElement("canvas");
        c.width=sideVideo.videoWidth; c.height=sideVideo.videoHeight;
        c.getContext("2d").drawImage(sideVideo,0,0);
        res(c.toDataURL("image/jpeg").split(",")[1]);
      } else if (uploadedImageData){
        const p=uploadedImageData.split(",");
        p[1]? res(p[1]) : rej("Bad dataURL");
      } else rej("No frame");
    });
  }
  function captureSegFrame(){
    return new Promise((res,rej)=>{
      if (segMode.value==="realsense_seg"){
        const p=segImg.src.split(",");
        p[1]? res(p[1]) : rej("No RealSense frame");
      }
      else if (segMode.value==="seg"){
        if (sideCamModeSelect.value==="camera"&&localStream){
          const c=document.createElement("canvas");
          c.width=segVideo.videoWidth; c.height=segVideo.videoHeight;
          c.getContext("2d").drawImage(segVideo,0,0);
          res(c.toDataURL("image/jpeg").split(",")[1]);
        } else {
          const p=uploadedImageData.split(",");
          p[1]? res(p[1]) : rej("No uploaded image");
        }
      } else rej("Unsupported mode");
    });
  }
  
  /****************************************************
   * CHAT (Window4)
   ****************************************************/
  function addChatMessage(sender,msg){
    if (chatMessages.children.length>1000) chatMessages.removeChild(chatMessages.firstChild);
    const dv=document.createElement("div");
    dv.innerHTML=`<strong>${sender}:</strong> ${msg}`;
    chatMessages.appendChild(dv);
    chatMessages.scrollTop = chatMessages.scrollHeight;
  }
  

/****************************************************
 * CHAT (Window4)  — send a line to the back-end
 ****************************************************/
async function sendChat(customText){
  const txt       = (customText || chatInput.value).trim();
  if (!txt) return;

  chatInput.value = "";
  addChatMessage("You", txt);

  //-------------------------------------------------
  // Freeze the current Seg frame (if not already)
  //-------------------------------------------------
  let frameB64 = "";
  try {
    frameB64   = await captureSegFrame();
    segFrozen  = true;
    clearInterval(realsenseSegTimer);
    if (segMode.value === "seg" && localStream) {
      segVideo.pause();
      segVideo.srcObject = null;
    }
    segImg.src            = "data:image/jpeg;base64," + frameB64;
    segImg.style.display  = "block";
    segVideo.style.display= "none";
  } catch {}

  //-------------------------------------------------
  // Show waiting message
  //-------------------------------------------------
  addChatMessage(
    "AAU Agent",
    "Finding object(s) and distance(s), please wait a few seconds"
  );

  //-------------------------------------------------
  // Call the Flask back-end
  //-------------------------------------------------
  let d = null;
  try {
    const resp = await fetch("/chat", {
      method : "POST",
      headers: { "Content-Type":"application/json" },
      body   : JSON.stringify({
        text      : txt,
        seg_input : segMode.value,
        seg_frame : frameB64
      })
    });

    if (!resp.ok){
      const errText = (await resp.text()).slice(0,120);
      addChatMessage("AAU Agent", `Server error (${resp.status}): ${errText}`);
      return;
    }
    d = await resp.json();
  }
  catch(e){
    console.error(e);
    addChatMessage("AAU Agent", "Error: " + e);
    return;
  }

  //-------------------------------------------------
  // Show overlay frame (segmentation)
  //-------------------------------------------------
  if (d.seg_frame) {
    segImg.src = "data:image/jpeg;base64," + d.seg_frame;
  }

  //-------------------------------------------------
  // Show geometry info in chat
  //-------------------------------------------------
  if (d.geometry_msg){
    addChatMessage("AAU Agent", d.geometry_msg);
  }

  //-------------------------------------------------
  // Always show the interim reply (should be the "please wait" string)
  //-------------------------------------------------
  // (If you want to show LLM answer after, add: addChatMessage("AAU Agent", d.reply);)
}


chatSendBtn.addEventListener("click",()=>sendChatStream());
chatInput.addEventListener("keyup",e=>{ if(e.key==="Enter") sendChatStream(); });

  
  /****************************************************
   * LLM Console
   ****************************************************/
  function logToConsole(msg){
    if (llmConsole.children.length>1000) llmConsole.removeChild(llmConsole.firstChild);
    const dv=document.createElement("div");
    dv.textContent=msg;
    llmConsole.appendChild(dv);
    llmConsole.scrollTop=llmConsole.scrollHeight;
  }
  </script>
  