<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AAU Robot Dashboard</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    /* Overall Grid: 3 rows, 2 columns */
    #dashboard {
      display: grid;
      grid-template-rows: 25% 25% 50%;
      grid-template-columns: 50% 50%;
      width: 100vw;
      height: 100vh;
      min-width: 1920px;
      min-height: 1080px;
      box-sizing: border-box;
      overflow: hidden;
    }
    .panel {
      border: 1px solid #444;
      background: #2a2a2a;
      position: relative;
      display: flex;
      flex-direction: column;
      padding: 8px;
      box-sizing: border-box;
    }
    .panel-title {
      position: absolute;
      top: 8px;
      left: 8px;
      font-weight: bold;
      color: #fff;
      z-index: 2;
    }
    /* For video/image in each window */
    .media-container {
      width: 100%;
      height: 100%;
      display: flex;
      align-items: center;
      justify-content: center;
      overflow: hidden;
      position: relative;
    }
    /* Keep video/image scaled to container height */
    .media-content {
      max-height: 100%;
      max-width: 100%;
      object-fit: contain;
      display: block;
    }
    /* Overlay for image mode if no image is chosen */
    #uploadButton {
      position: absolute;
      top: 0; left: 0;
      width: 100%; height: 100%;
      display: none;
      background: rgba(0,0,0,0.5);
      color: #4af;
      font-size: 24px;
      align-items: center;
      justify-content: center;
      cursor: pointer;
      z-index: 4;
    }
    #fileUploadInput {
      display: none;
    }
    .console-area {
      background: #111;
      border: 1px solid #4af;
      font-family: monospace;
      padding: 4px;
      overflow-y: auto;
      flex: 1;
    }
    .neon-btn {
      background-color: #222;
      color: #4af;
      border: 1px solid #4af;
      transition: all 0.2s ease-in-out;
    }
    .neon-btn:hover {
      background-color: #4af;
      color: #111;
      box-shadow: 0 0 8px #4af;
    }
    select {
      background-color: #2a2a2a;
      color: #4af;
      border: 1px solid #4af;
      padding: 4px;
    }
  </style>
</head>
<body class="bg-gray-900 text-green-300">

<div id="dashboard">
  <!-- Row1, Col1: Side Camera (Window1) -->
  <div class="panel" style="grid-row:1; grid-column:1;">
    <div class="panel-title">Side Camera (Window1)</div>
    <!-- "camera" or "image" -->
    <select id="sideCamModeSelect" style="position:absolute; top:8px; right:8px; z-index:5;">
      <option value="camera">SideCam</option>
      <option value="image">Image</option>
    </select>
    <div id="sideCamContainer" class="media-container">
      <!-- If "camera", show a live video feed -->
      <video id="sideVideo" class="media-content" autoplay muted playsinline></video>
      <!-- If "image", show an uploaded image -->
      <img id="sideImage" class="media-content" src="" alt="UploadedImage" style="display:none;">
      <!-- Overlay for uploading an image if none is chosen yet -->
      <div id="uploadButton">Click to upload or drag &amp; drop</div>
      <input type="file" id="fileUploadInput" accept="image/*">
    </div>
  </div>

  <!-- Row1, Col2: Model Selection (Window5) -->
  <div class="panel" style="grid-row:1; grid-column:2; justify-content:center; align-items:center;">
    <div class="panel-title">Model Selection (Window5)</div>
    <div style="margin-top:2rem; display:flex; flex-direction:column; gap:1rem;">
      <div>
        <label>VLM:</label>
        <select id="vlmSelect">
          <option>OpenVLM_1</option>
          <option>OpenVLM_2</option>
          <option>OpenVLM_3</option>
        </select>
      </div>
      <div>
        <label>LLM:</label>
        <select id="llmSelect">
          <option>ChatGPT</option>
          <option>Llama</option>
          <option>Claude</option>
        </select>
      </div>
    </div>
  </div>

  <!-- Row2, Col1: Window2 (Seg) + Window3 (Depth) side by side -->
  <div class="panel" style="grid-row:2; grid-column:1; display:flex; flex-direction:row; padding:0;">
    <!-- Window2: Seg -->
    <div id="segContainer" class="media-container" style="flex:1; border-right:1px solid #333;">
      <div class="panel-title">Seg (Window2)</div>
      <video id="segVideo" class="media-content" autoplay muted playsinline></video>
      <img id="segImg" class="media-content" src="https://via.placeholder.com/320x180?text=Seg" alt="SegOutput" style="display:none;">
      <select id="segMode" style="position:absolute; top:8px; right:8px; z-index:5;">
        <option value="off">Off</option>
        <option value="seg">Window 1 Seg</option>
        <option value="realsense_seg">RealSense RGB</option>
      </select>
    </div>

    <!-- Window3: Depth -->
    <div id="depthContainer" class="media-container" style="flex:1;">
      <div class="panel-title">Depth (Window3)</div>
      <img id="depthImg" class="media-content" src="https://via.placeholder.com/320x180?text=Depth" alt="DepthOutput">
      <select id="depthMode" style="position:absolute; top:8px; right:8px; z-index:5;"></select>
    </div>
  </div>

  <!-- Row2, Col2: Robot Control (Window6) -->
  <div class="panel" style="grid-row:2; grid-column:2; justify-content:center; align-items:center;">
    <div class="panel-title">Robot Control (Window6)</div>
    <div style="margin-top:2rem; display:flex; gap:1rem;">
      <button class="neon-btn px-3 py-1" onclick="sendChat('move forward')">Forward</button>
      <button class="neon-btn px-3 py-1" onclick="sendChat('2 to the left')">Left x2</button>
      <button class="neon-btn px-3 py-1" onclick="sendChat('turn right')">Right</button>
    </div>
  </div>

  <!-- Row3, Col1: Chat (Window4) -->
  <div class="panel" style="grid-row:3; grid-column:1;">
    <div class="panel-title">Chat (Window4)</div>
    <div id="chatMessages" style="flex:1; overflow-y:auto; background:#111; border:1px solid #666; padding:4px; margin-top:30px;"></div>
    <div style="margin-top:8px; display:flex;">
      <input type="text" id="chatInput" class="bg-gray-800 text-green-300 border border-green-500 px-2 py-1 flex-1" placeholder="Type command...">
      <button id="chatSendBtn" class="neon-btn px-3 py-1" style="margin-left:8px;">Send</button>
    </div>
  </div>

  <!-- Row3, Col2: LLM Reasoning (Window7) -->
  <div class="panel" style="grid-row:3; grid-column:2; display:flex; flex-direction:column;">
    <div class="panel-title">LLM Reasoning (Window7)</div>
    <div id="llmConsole" class="console-area" style="margin-top:30px;"></div>
  </div>
</div>

<script>
/****************************************************
 * GLOBALS
 ****************************************************/
let localStream       = null;
let uploadedImageData = "";
let depthInterval     = null;

/****************************************************
 * ON PAGE LOAD: fetch camera_info, then set up
 ****************************************************/
window.addEventListener("DOMContentLoaded", async () => {
  try {
    const resp = await fetch("/camera_info");
    if (!resp.ok) throw new Error("camera_info error: " + resp.status);
    const info = await resp.json();
    console.log("[camera_info]", info);

    // If RealSense is not available, remove RealSense options from Depth dropdown once we build it
    // We'll do that in updateDepthDropdown after we see sideCamModeSelect's value.
    window.realsenseAvailable = info.realsense_available === true;
  } catch (err) {
    console.warn("Could not fetch camera_info:", err);
    window.realsenseAvailable = false; // fallback
  }

  updateDepthDropdown(); // build the initial dropdown
  document.getElementById("sideCamModeSelect").dispatchEvent(new Event("change"));
});

/****************************************************
 * 1) Side Camera (Window1) => "camera" or "image"
 ****************************************************/
const sideCamModeSelect = document.getElementById("sideCamModeSelect");
const sideVideo         = document.getElementById("sideVideo");
const sideImage         = document.getElementById("sideImage");
const uploadButton      = document.getElementById("uploadButton");
const fileUploadInput   = document.getElementById("fileUploadInput");
const sideCamContainer  = document.getElementById("sideCamContainer");

sideCamModeSelect.addEventListener("change", () => {
  const mode = sideCamModeSelect.value;

  if (mode === "camera") {
    stopSideCam();
    startSideCam();

    sideVideo.style.display = "block";
    sideImage.style.display = "none";
    uploadButton.style.display = "none";
  } else {
    // "image"
    stopSideCam();

    // show user-chosen image or show "upload" overlay
    if (uploadedImageData) {
      sideImage.style.display = "block";
      sideImage.src = uploadedImageData;
      uploadButton.style.display = "none";
    } else {
      sideImage.style.display = "none";
      uploadButton.style.display = "flex";
    }

    sideVideo.style.display = "none";
  }

  // Refresh Depth dropdown
  updateDepthDropdown();
});

async function startSideCam() {
  try {
    localStream = await navigator.mediaDevices.getUserMedia({
      video: { width:1280, height:720, frameRate:20 },
      audio: false
    });
    sideVideo.srcObject = localStream;

    // Also mirror to Seg window if segMode is "seg"
    if (segMode.value === "seg") {
      segVideo.srcObject = localStream;
    }
  } catch(err) {
    console.error("Camera error:", err);
  }
}
function stopSideCam() {
  if (localStream) {
    localStream.getTracks().forEach(t => t.stop());
  }
  localStream = null;
  segVideo.srcObject = null;
}

// Upload logic
uploadButton.addEventListener("click", () => fileUploadInput.click());
fileUploadInput.addEventListener("change", ev => {
  if (ev.target.files.length > 0) {
    const f = ev.target.files[0];
    readAndSetImage(f);
  }
});
sideCamContainer.addEventListener("dragover", e => {
  e.preventDefault();
  e.stopPropagation();
  sideCamContainer.style.border = "2px dashed #4af";
});
sideCamContainer.addEventListener("dragleave", e => {
  e.preventDefault();
  e.stopPropagation();
  sideCamContainer.style.border = "none";
});
sideCamContainer.addEventListener("drop", e => {
  e.preventDefault();
  e.stopPropagation();
  sideCamContainer.style.border = "none";
  if (sideCamModeSelect.value === "image") {
    const files = e.dataTransfer.files;
    if (files.length > 0) readAndSetImage(files[0]);
  }
});

function readAndSetImage(file) {
  const rdr = new FileReader();
  rdr.onload = (evt) => {
    uploadedImageData = evt.target.result;
    sideImage.src = uploadedImageData;
    sideImage.style.display = "block";
    uploadButton.style.display = "none";

    // If we have Seg "on" and not frozen, show it in segImg
    if (segMode.value === "seg" && !segFrozen) {
      segImg.src = uploadedImageData;
    }

    // If Depth is "image_depth", do a single call
    if (depthMode.value === "image_depth") {
      processImageDepth();
    }
  };
  rdr.readAsDataURL(file);
}

/****************************************************
 * 2) Segmentation (Window2)
 ****************************************************/
const segMode      = document.getElementById("segMode");
const segVideo     = document.getElementById("segVideo");
const segImg       = document.getElementById("segImg");
const segContainer = document.getElementById("segContainer");

let segFrozen    = false;
let isSegmenting = false;
let realsenseSegInterval = null;

function startRealsenseSegLoop() {
  stopRealsenseSegLoop();
  // Adjust the polling interval here (250ms => approx. 4 FPS)
  realsenseSegInterval = setInterval(async () => {
    try {
      const resp = await fetch("/process_realsense_seg", {
        method: "POST",
        headers: { "Content-Type": "application/json" }
      });
      if (!resp.ok) throw new Error("Realsense seg error: " + resp.status);
      const data = await resp.json();
      if (data.frame) {
        // Update segImg so that segmentation window shows the RealSense image.
        segImg.src = "data:image/jpeg;base64," + data.frame;
      }
    } catch (e) {
      console.error("Realsense seg loop error:", e);
    }
  }, 250);
}

function stopRealsenseSegLoop() {
  if (realsenseSegInterval) {
    clearInterval(realsenseSegInterval);
    realsenseSegInterval = null;
  }
}


function stopRealsenseSegLoop() {
  if (realsenseSegInterval) {
    clearInterval(realsenseSegInterval);
    realsenseSegInterval = null;
  }
}

segMode.addEventListener("change", () => {
  if (segMode.value === "seg") {
    segFrozen = false;
    // Use the standard webcam or uploaded image, as before
    if (localStream && sideCamModeSelect.value === "camera") {
      segVideo.srcObject = localStream;
      segVideo.style.display = "block";
      segImg.style.display = "none";
    } else if (sideCamModeSelect.value === "image" && uploadedImageData) {
      segFrozen = false;
      segVideo.style.display = "none";
      segImg.style.display = "block";
      segImg.src = uploadedImageData;
    }
    stopRealsenseSegLoop();
    } else if (segMode.value === "realsense_seg") {
    // When using RealSense for segmentation, continue streaming the side camera in Window1
    // but update the segmentation window to show RealSense frames.
    segImg.style.display = "block";
    segVideo.style.display = "none";
    // Do NOT call stopSideCam() so that Window1 keeps streaming.
    startRealsenseSegLoop(); // Begin fetching RealSense frames.
  } else {
    // "off" mode: Hide everything.
    segFrozen = false;
    segVideo.style.display = "none";
    segImg.style.display = "none";
    segImg.src = "https://via.placeholder.com/320x180?text=Seg";
    segVideo.srcObject = null;
    stopRealsenseSegLoop();
  }
});

/**
 * Two-click approach:
 *   1) If not frozen => freeze + run SAM
 *   2) If frozen => revert
 */
 segContainer.addEventListener("click", async (ev) => {
  if (segMode.value !== "seg" && segMode.value !== "realsense_seg") return;
  if (isSegmenting) return;
  if (ev.target === segMode) return;

  if (!segFrozen) {
    segFrozen = true;
    isSegmenting = true;

    // Always show segImg to display the current frame.
    segVideo.style.display = "none";
    segImg.style.display   = "block";

    try {
      // Capture the current frame based on the active seg mode.
      let freezeB64 = await captureSegFrame();
      segImg.src = "data:image/jpeg;base64," + freezeB64;

      const rect = segContainer.getBoundingClientRect();
      const nx = (ev.clientX - rect.left) / rect.width;
      const ny = (ev.clientY - rect.top) / rect.height;

      const r = await fetch("/process_seg", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          frame: freezeB64,
          clicked_x: nx,
          clicked_y: ny
        })
      });
      if (r.ok) {
        const d = await r.json();
        segImg.src = "data:image/jpeg;base64," + d.frame;
      }
      // In RealSense segmentation mode, stop the polling loop so the result remains frozen.
      if (segMode.value === "realsense_seg") {
        stopRealsenseSegLoop();
      }
    } catch (e) {
      console.error("Seg error:", e);
    } finally {
      isSegmenting = false;
    }
  } else {
    // Toggle segmentation off, i.e. resume the live stream.
    segFrozen = false;
    if (segMode.value === "seg") {
      if (sideCamModeSelect.value === "camera" && localStream) {
        segVideo.style.display = "block";
        segVideo.srcObject = localStream;
        segImg.style.display   = "none";
      } else {
        segVideo.style.display = "none";
        segImg.style.display   = "block";
        segImg.src = uploadedImageData || "https://via.placeholder.com/320x180?text=Seg";
      }
    } else if (segMode.value === "realsense_seg") {
      // Resume the RealSense streaming loop.
      startRealsenseSegLoop();
    }
  }
});

function captureVideoFrame(videoEl) {
  return new Promise((resolve, reject) => {
    try {
      const c = document.createElement("canvas");
      c.width  = videoEl.videoWidth;
      c.height = videoEl.videoHeight;
      c.getContext("2d").drawImage(videoEl, 0, 0);
      const b64 = c.toDataURL("image/jpeg").split(",")[1];
      resolve(b64);
    } catch (err) {
      reject(err);
    }
  });
}

function captureSegFrame() {
  return new Promise((resolve, reject) => {
    if (segMode.value === "realsense_seg") {
      if (!segImg.src) return reject("No RealSense seg frame available");
      const parts = segImg.src.split(",");
      if (parts.length > 1) {
        resolve(parts[1]);
      } else {
        reject("Invalid segImg src");
      }
    } else if (segMode.value === "seg") {
      if (sideCamModeSelect.value === "camera" && localStream) {
        const c = document.createElement("canvas");
        c.width  = segVideo.videoWidth;
        c.height = segVideo.videoHeight;
        c.getContext("2d").drawImage(segVideo, 0, 0);
        const b64 = c.toDataURL("image/jpeg").split(",")[1];
        resolve(b64);
      } else {
        if (!uploadedImageData) {
          return reject("No uploaded image");
        }
        const parts = uploadedImageData.split(",");
        if (parts.length > 1) {
          resolve(parts[1]);
        } else {
          reject("Invalid uploaded image data");
        }
      }
    } else {
      reject("Unsupported seg mode");
    }
  });
}


/****************************************************
 * 3) Depth (Window3)
 ****************************************************/
const depthMode = document.getElementById("depthMode");
const depthImg  = document.getElementById("depthImg");

function updateDepthDropdown() {
  // "camera" => show sidecam modes + local cam, realsense, etc.
  // "image"  => show "image_depth"
  // We'll always show realsense or local if realsenseAvailable or local cams exist
  if (sideCamModeSelect.value === "camera") {
    // Basic set
    let opts = `
      <option value="off">Off</option>
      <option value="sidecam_depth">SideCam DepthAnything</option>
      <option value="other">Other (Inverse)</option>
    `;
    // If realsense is available, add those
    if (window.realsenseAvailable) {
      opts += `
        <option value="realsense_rgb_anything">RealSense RGB + DepthAnything</option>
        <option value="realsense_depth">RealSense Depth</option>
      `;
    }
    depthMode.innerHTML = opts;
  } else {
    // "image" => just off or "image_depth"
    depthMode.innerHTML = `
      <option value="off">Off</option>
      <option value="image_depth">Image Depth Anything</option>
    `;
  }
}

depthMode.addEventListener("change", () => {
  stopDepthLoop();
  depthImg.src = "https://via.placeholder.com/320x180?text=Depth";
  const v = depthMode.value;
  if (v === "off") {
    fetch("/process_depth", {
      method:"POST",
      headers:{"Content-Type":"application/json"},
      body: JSON.stringify({ camera_mode:"off" })
    });
  } else if (sideCamModeSelect.value === "camera") {
    // If we picked something besides "off" in camera mode => do a loop
    // "sidecam_depth", "local_depth_anything", "realsense_rgb_anything", "realsense_depth", "other"
    startDepthLoop(v);
  } else {
    // "image_depth" => single call
    processImageDepth();
  }
});

function startDepthLoop(cameraMode) {
  stopDepthLoop();
  depthInterval = setInterval(async () => {
    try {
      let b64 = "";
      // For "sidecam_depth" or "other", we want to pass the current sideVideo frame
      // For local_depth_anything, the server handles local camera itself, so we might not need a frame
      // but let's see your code. We'll just pass the sideVideo frame for "sidecam_depth" or "other"
      if (cameraMode === "sidecam_depth" || cameraMode === "other" || cameraMode === "default_anything") {
        b64 = await captureSideFrame(); // from sideVideo
      }
      // local_depth_anything or realsense => the server grabs frames from local camera or realsense
      // but some code might expect a frame anyway. We'll pass an empty string if we don't want to
      // or always pass it if the server doesn't mind. For safety, let's do the same for "other".
      // This depends on your server. We'll keep it simple.
      const resp = await fetch("/process_depth", {
        method: "POST",
        headers: { "Content-Type":"application/json" },
        body: JSON.stringify({
          camera_mode: cameraMode,
          local_idx: 0,
          frame: b64
        })
      });
      if (!resp.ok) throw new Error("Depth error: " + resp.status);
      const data = await resp.json();
      if (data.frame) {
        depthImg.src = "data:image/jpeg;base64," + data.frame;
      }
    } catch(e) {
      console.error("Depth loop error:", e);
    }
  }, 500);
}

function stopDepthLoop() {
  if (depthInterval) {
    clearInterval(depthInterval);
    depthInterval = null;
  }
}

// If "image_depth", we do a single call whenever user changes
async function processImageDepth() {
  try {
    const b64 = await captureSideFrame();
    const resp = await fetch("/process_depth", {
      method: "POST",
      headers: { "Content-Type":"application/json" },
      body: JSON.stringify({
        camera_mode: "image_depth",
        local_idx: 0,
        frame: b64
      })
    });
    if (!resp.ok) throw new Error("Depth error: " + resp.status);
    const data = await resp.json();
    if (data.frame) {
      depthImg.src = "data:image/jpeg;base64," + data.frame;
    }
  } catch(e){
    console.error("Image depth error:", e);
  }
}

/** captureSideFrame => base64 from sideVideo or from uploadedImageData if in "image" mode. */
function captureSideFrame() {
  return new Promise((resolve, reject) => {
    if (sideCamModeSelect.value === "camera") {
      if (!sideVideo.srcObject) return reject("No sidecam feed");
      try {
        const c = document.createElement("canvas");
        c.width = sideVideo.videoWidth;
        c.height= sideVideo.videoHeight;
        c.getContext("2d").drawImage(sideVideo, 0, 0, c.width, c.height);
        const b64 = c.toDataURL("image/jpeg").split(",")[1];
        resolve(b64);
      } catch(e){
        reject(e);
      }
    } else {
      // "image"
      if (!uploadedImageData) {
        return reject("No uploaded image");
      }
      const parts = uploadedImageData.split(",");
      if (parts.length > 1) {
        resolve(parts[1]); // the base64 part
      } else {
        // not standard dataURL?
        reject("Invalid dataURL in uploadedImageData");
      }
    }
  });
}

/****************************************************
 * 4) Chat (Window4)
 ****************************************************/
const chatMessages = document.getElementById("chatMessages");
const chatInput    = document.getElementById("chatInput");
const chatSendBtn  = document.getElementById("chatSendBtn");

chatSendBtn.addEventListener("click", () => sendChat());
chatInput.addEventListener("keyup", (e) => { 
  if (e.key === "Enter") sendChat();
});

function addChatMessage(sender, msg) {
  if (chatMessages.children.length >= 1000) {
    chatMessages.removeChild(chatMessages.firstChild);
  }
  const dv = document.createElement("div");
  dv.innerHTML = `<strong>${sender}:</strong> ${msg}`;
  chatMessages.appendChild(dv);
  chatMessages.scrollTop = chatMessages.scrollHeight;
}

async function sendChat(customText) {
  const userText = customText || chatInput.value.trim();
  if (!userText) return;
  chatInput.value = "";
  addChatMessage("You", userText);

  try {
    // Capture the current seg window frame.
    let segFrame = await captureSegFrame().catch(err => null);
    const segInput = document.getElementById("segMode").value;
    
    const resp = await fetch("/chat", {
      method:"POST",
      headers: {"Content-Type":"application/json"},
      body: JSON.stringify({ 
        text: userText,
        seg_input: segInput,
        seg_frame: segFrame
      })
    });
    if (!resp.ok) throw new Error("Chat request failed: " + resp.status);
    const d = await resp.json();
    addChatMessage("AAU Agent", d.reply);
    
    // Update the SEG window with the candidate overlay image (freeze it).
    if (d.seg_frame) {
      const segImg = document.getElementById("segImg");
      segImg.src = "data:image/jpeg;base64," + d.seg_frame;
      segImg.style.display = "block";
      const segVideo = document.getElementById("segVideo");
      if (segVideo) segVideo.style.display = "none";
    }
  } catch(err) {
    console.error(err);
    addChatMessage("AAU Agent", "Error: " + err.toString());
  }
}


/****************************************************
 * 5) LLM Reasoning (Window7)
 ****************************************************/
const llmConsole = document.getElementById("llmConsole");
function logToConsole(msg){
  if (llmConsole.children.length >= 1000){
    llmConsole.removeChild(llmConsole.firstChild);
  }
  const dv = document.createElement("div");
  dv.textContent = msg;
  llmConsole.appendChild(dv);
  llmConsole.scrollTop = llmConsole.scrollHeight;
}
</script>
</body>
</html>
