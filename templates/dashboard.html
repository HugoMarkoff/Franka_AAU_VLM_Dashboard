<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AAU Robot Dashboard</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    /* Overall Grid: 3 rows, 2 columns */
    #dashboard {
      display: grid;
      grid-template-rows: 25% 25% 50%;
      grid-template-columns: 50% 50%;
      width: 100vw;
      height: 100vh;
      min-width: 1920px;
      min-height: 1080px;
      box-sizing: border-box;
      overflow: hidden;
    }
    .panel {
      border: 1px solid #444;
      background: #2a2a2a;
      position: relative;
      display: flex;
      flex-direction: column;
      padding: 8px;
      box-sizing: border-box;
    }
    .panel-title {
      position: absolute;
      top: 8px;
      left: 8px;
      font-weight: bold;
      color: #fff;
      z-index: 2;
    }
    /* For video/image in each window */
    .media-container {
      width: 100%;
      height: 100%;
      display: flex;
      align-items: center;
      justify-content: center;
      overflow: hidden;
      position: relative;
    }
    /* Keep video/image scaled to container height */
    .media-content {
      max-height: 100%;
      max-width: 100%;
      object-fit: contain;
      display: block;
    }
    /* Overlay for image mode if no image is chosen */
    #uploadButton {
      position: absolute;
      top: 0; left: 0;
      width: 100%; height: 100%;
      display: none;
      background: rgba(0,0,0,0.5);
      color: #4af;
      font-size: 24px;
      align-items: center;
      justify-content: center;
      cursor: pointer;
      z-index: 4;
    }
    #fileUploadInput {
      display: none;
    }
    .console-area {
      background: #111;
      border: 1px solid #4af;
      font-family: monospace;
      padding: 4px;
      overflow-y: auto;
      flex: 1;
    }
    .neon-btn {
      background-color: #222;
      color: #4af;
      border: 1px solid #4af;
      transition: all 0.2s ease-in-out;
    }
    .neon-btn:hover {
      background-color: #4af;
      color: #111;
      box-shadow: 0 0 8px #4af;
    }
    select {
      background-color: #2a2a2a;
      color: #4af;
      border: 1px solid #4af;
      padding: 4px;
    }
  </style>
</head>
<body class="bg-gray-900 text-green-300">

<div id="dashboard">
  <!-- Row1, Col1: Side Camera (Window1) -->
  <div class="panel" style="grid-row:1; grid-column:1;">
    <div class="panel-title">Side Camera (Window1)</div>
    <!-- "camera" or "image" -->
    <select id="sideCamModeSelect" style="position:absolute; top:8px; right:8px; z-index:5;">
      <option value="camera">SideCam</option>
      <option value="image">Image</option>
    </select>
    <div id="sideCamContainer" class="media-container">
      <!-- If "camera", show a live video feed -->
      <video id="sideVideo" class="media-content" autoplay muted playsinline></video>
      <!-- If "image", show an uploaded image -->
      <img id="sideImage" class="media-content" src="" alt="UploadedImage" style="display:none;">
      <!-- Overlay for uploading an image if none is chosen yet -->
      <div id="uploadButton">Click to upload or drag &amp; drop</div>
      <input type="file" id="fileUploadInput" accept="image/*">
    </div>
  </div>

  <!-- Row1, Col2: Model Selection (Window5) -->
  <div class="panel" style="grid-row:1; grid-column:2; justify-content:center; align-items:center;">
    <div class="panel-title">Model Selection (Window5)</div>
    <div style="margin-top:2rem; display:flex; flex-direction:column; gap:1rem;">
      <div>
        <label>VLM:</label>
        <select id="vlmSelect">
          <option>OpenVLM_1</option>
          <option>OpenVLM_2</option>
          <option>OpenVLM_3</option>
        </select>
      </div>
      <div>
        <label>LLM:</label>
        <select id="llmSelect">
          <option>ChatGPT</option>
          <option>Llama</option>
          <option>Claude</option>
        </select>
      </div>
    </div>
  </div>

  <!-- Row2, Col1: Window2 (Seg) + Window3 (Depth) side by side -->
  <div class="panel" style="grid-row:2; grid-column:1; display:flex; flex-direction:row; padding:0;">
    <!-- Window2: Seg -->
    <div id="segContainer" class="media-container" style="flex:1; border-right:1px solid #333;">
      <div class="panel-title">Seg (Window2)</div>
      <video id="segVideo" class="media-content" autoplay muted playsinline></video>
      <img id="segImg" class="media-content" src="https://via.placeholder.com/320x180?text=Seg" alt="SegOutput" style="display:none;">
      <select id="segMode" style="position:absolute; top:8px; right:8px; z-index:5;">
        <option value="off">Off</option>
        <option value="seg">Window 1 Seg</option>
        <option value="realsense_seg">RealSense RGB</option>
      </select>
    </div>

    <!-- Window3: Depth -->
    <div id="depthContainer" class="media-container" style="flex:1;">
      <div class="panel-title">Depth (Window3)</div>
      <img id="depthImg" class="media-content" src="https://via.placeholder.com/320x180?text=Depth" alt="DepthOutput">
      <select id="depthMode" style="position:absolute; top:8px; right:8px; z-index:5;"></select>
    </div>
  </div>

  <!-- Row2, Col2: Robot Control (Window6) -->
  <div class="panel" style="grid-row:2; grid-column:2; justify-content:center; align-items:center;">
    <div class="panel-title">Robot Control (Window6)</div>
    <div style="margin-top:2rem; display:flex; gap:1rem;">
      <button class="neon-btn px-3 py-1" onclick="sendChat('move forward')">Forward</button>
      <button class="neon-btn px-3 py-1" onclick="sendChat('2 to the left')">Left x2</button>
      <button class="neon-btn px-3 py-1" onclick="sendChat('turn right')">Right</button>
    </div>
  </div>

  <!-- Row3, Col1: Chat (Window4) -->
  <div class="panel" style="grid-row:3; grid-column:1;">
    <div class="panel-title">Chat (Window4)</div>
    <div id="chatMessages" style="flex:1; overflow-y:auto; background:#111; border:1px solid #666; padding:4px; margin-top:30px;"></div>
    <div style="margin-top:8px; display:flex;">
      <input type="text" id="chatInput" class="bg-gray-800 text-green-300 border border-green-500 px-2 py-1 flex-1" placeholder="Type command...">
      <button id="chatSendBtn" class="neon-btn px-3 py-1" style="margin-left:8px;">Send</button>
    </div>
  </div>

  <!-- Row3, Col2: LLM Reasoning (Window7) -->
  <div class="panel" style="grid-row:3; grid-column:2; display:flex; flex-direction:column;">
    <div class="panel-title">LLM Reasoning (Window7)</div>
    <div id="llmConsole" class="console-area" style="margin-top:30px;"></div>
  </div>
</div>

<script>
  /****************************************************
   * ELEMENT REFS
   ****************************************************/
  const sideCamModeSelect = document.getElementById("sideCamModeSelect");
  const sideVideo         = document.getElementById("sideVideo");
  const sideImage         = document.getElementById("sideImage");
  const uploadButton      = document.getElementById("uploadButton");
  const fileUploadInput   = document.getElementById("fileUploadInput");
  const sideCamContainer  = document.getElementById("sideCamContainer");
  
  const segMode      = document.getElementById("segMode");
  const segVideo     = document.getElementById("segVideo");
  const segImg       = document.getElementById("segImg");
  const segContainer = document.getElementById("segContainer");
  
  const depthMode = document.getElementById("depthMode");
  const depthImg  = document.getElementById("depthImg");
  
  const chatMessages = document.getElementById("chatMessages");
  const chatInput    = document.getElementById("chatInput");
  const chatSendBtn  = document.getElementById("chatSendBtn");
  
  const llmConsole = document.getElementById("llmConsole");
  
  /****************************************************
   * STATE
   ****************************************************/
  let localStream        = null;
  let uploadedImageData  = "";
  let segFrozen          = false;
  let isSegmenting       = false;
  let realsenseSegTimer  = null;
  let depthTimer         = null;
  
  /****************************************************
   * PAGE LOAD
   ****************************************************/
  window.addEventListener("DOMContentLoaded", async () => {
    // fetch camera info for depth dropdown
    try {
      const res = await fetch("/camera_info");
      const info = await res.json();
      window.realsenseAvailable = info.realsense_available;
    } catch {
      window.realsenseAvailable = false;
    }
    updateDepthDropdown();
    sideCamModeSelect.dispatchEvent(new Event("change"));
  });
  
  /****************************************************
   * SIDE CAMERA (Window1)
   ****************************************************/
  sideCamModeSelect.addEventListener("change", () => {
    const mode = sideCamModeSelect.value;
    if (mode === "camera") {
      startSideCam();
      sideVideo.style.display = "block";
      sideImage.style.display = "none";
      uploadButton.style.display = "none";
    } else {
      stopSideCam();
      if (uploadedImageData) {
        sideImage.src = uploadedImageData;
        sideImage.style.display = "block";
        uploadButton.style.display = "none";
      } else {
        sideImage.style.display = "none";
        uploadButton.style.display = "flex";
      }
      sideVideo.style.display = "none";
    }
    updateDepthDropdown();
  });
  
  async function startSideCam() {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { width:1280, height:720, frameRate:20 },
        audio: false
      });
      localStream = stream;
      sideVideo.srcObject = stream;
      // mirror to Seg window if active
      if (segMode.value === "seg") {
        segVideo.srcObject = stream;
      }
    } catch (e) {
      console.error("startSideCam:", e);
    }
  }
  function stopSideCam() {
    if (localStream) {
      localStream.getTracks().forEach(t=>t.stop());
      localStream = null;
    }
    segVideo.srcObject = null;
  }
  
  uploadButton.addEventListener("click", () => fileUploadInput.click());
  fileUploadInput.addEventListener("change", evt => {
    if (!evt.target.files.length) return;
    const file = evt.target.files[0];
    const rdr = new FileReader();
    rdr.onload = () => {
      uploadedImageData = rdr.result;
      sideImage.src = uploadedImageData;
      sideImage.style.display = "block";
      uploadButton.style.display = "none";
      if (segMode.value==="seg" && !segFrozen) {
        segImg.src = uploadedImageData;
        segImg.style.display = "block";
        segVideo.style.display = "none";
      }
      if (depthMode.value==="image_depth") processImageDepth();
    };
    rdr.readAsDataURL(file);
  });
  
  /****************************************************
   * SEGMENTATION (Window2)
   ****************************************************/
  segMode.addEventListener("change", () => {
    segFrozen = false;
    clearInterval(realsenseSegTimer);
    if (segMode.value === "seg") {
      if (localStream && sideCamModeSelect.value==="camera") {
        segVideo.srcObject = localStream;
        segVideo.style.display = "block";
        segImg.style.display = "none";
      } else {
        segVideo.style.display = "none";
        segImg.style.display = "block";
        segImg.src = uploadedImageData || segImg.src;
      }
    }
    else if (segMode.value==="realsense_seg") {
      segVideo.style.display = "none";
      segImg.style.display = "block";
      realsenseSegTimer = setInterval(fetchRealsenseSeg, 250);
    }
    else {
      segVideo.style.display = "none";
      segImg.style.display = "none";
    }
  });
  
  async function fetchRealsenseSeg() {
    try {
      const resp = await fetch("/process_realsense_seg",{ method:"POST" });
      if (!resp.ok) throw "";
      const d = await resp.json();
      if (d.frame) segImg.src = "data:image/jpeg;base64,"+d.frame;
    } catch {}
  }
  
// Freeze the Seg window — no more frames will arrive until we unfreeze
function freezeSegWindow(base64Frame) {
  segFrozen    = true;
  isSegmenting = true;
  clearInterval(realsenseSegTimer);

  // disable camera track & pause
  if (segMode.value === "seg" && localStream) {
    localStream.getVideoTracks().forEach(t => t.enabled = false);
    segVideo.pause();
  }

  // swap to your frozen JPEG
  segImg.src            = "data:image/jpeg;base64," + base64Frame;
  segVideo.style.display = "none";
  segImg.style.display   = "block";
}

// Unfreeze & resume your live feed
function unfreezeSegWindow() {
  segFrozen = false;
  fetch("/reset_seg", { method:"POST" }).catch();

  if (segMode.value === "seg" && localStream) {
    // re-enable track and replay
    localStream.getVideoTracks().forEach(t => t.enabled = true);
    segVideo.srcObject = localStream;
    segVideo.play();
    segVideo.style.display = "block";
    segImg.style.display   = "none";
  }
  else if (segMode.value === "realsense_seg") {
    realsenseSegTimer = setInterval(fetchRealsenseSeg, 250);
  }
}


segContainer.addEventListener("click", async ev => {
  if (!["seg","realsense_seg"].includes(segMode.value) || isSegmenting) return;

  // — FIRST CLICK: freeze and segment —
  if (!segFrozen) {
    try {
      const frameB64 = await captureSegFrame();
      freezeSegWindow(frameB64);

      // translate click → normalized image coords
      const rr = segImg.getBoundingClientRect();
      const nx = (ev.clientX - rr.left) / rr.width;
      const ny = (ev.clientY - rr.top)  / rr.height;

      const resp = await fetch("/process_seg", {
        method:  "POST",
        headers: { "Content-Type":"application/json" },
        body:    JSON.stringify({ frame: frameB64, clicked_x: nx, clicked_y: ny })
      });
      if (resp.ok) {
        const dd = await resp.json();
        if (dd.object_info) {
          addChatMessage(
            "AAU Agent",
            `Center: ${dd.object_info.center_xyz_m.map(v=>v.toFixed(3)).join(', ')} m; ` +
            `distance ${dd.object_info.distance_m.toFixed(3)} m; ` +
            `W×H ${(dd.object_info.width_m*100).toFixed(1)}×${(dd.object_info.height_m*100).toFixed(1)} cm`
          );
        }
        // update overlay on your frozen image
        segImg.src = "data:image/jpeg;base64," + dd.frame;
      }
    } catch(e) {
      console.error("Seg error:", e);
    } finally {
      isSegmenting = false;
    }
  }
  // — SECOND CLICK: unfreeze —
  else {
    unfreezeSegWindow();
  }
});

  /****************************************************
   * DEPTH (Window3)
   ****************************************************/
  function updateDepthDropdown(){
    if (sideCamModeSelect.value==="camera"){
      let opts = `
        <option value="off">Off</option>
        <option value="sidecam_depth">SideCam DepthAnything</option>
        <option value="other">Other (Inverse)</option>
      `;
      if (window.realsenseAvailable){
        opts+=`
          <option value="realsense_rgb_anything">RealSense RGB+DepthAnything</option>
          <option value="realsense_depth">RealSense Depth</option>
        `;
      }
      depthMode.innerHTML = opts;
    } else {
      depthMode.innerHTML = `
        <option value="off">Off</option>
        <option value="image_depth">Image Depth Anything</option>
      `;
    }
  }
  
  depthMode.addEventListener("change", () => {
    clearInterval(depthTimer);
    depthImg.src="https://via.placeholder.com/320x180?text=Depth";
    const v=depthMode.value;
    if (v==="off"){
      fetch("/process_depth",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({camera_mode:"off"})});
    }
    else if (sideCamModeSelect.value==="camera"){
      depthTimer=setInterval(() => processDepth(v),500);
    }
    else{
      processImageDepth();
    }
  });
  
  async function processDepth(mode){
    try {
      let b64="";
      if (mode==="sidecam_depth"||mode==="other"){
        b64 = await captureSideFrame();
      }
      const r = await fetch("/process_depth",{
        method:"POST",
        headers:{"Content-Type":"application/json"},
        body:JSON.stringify({ camera_mode:mode, local_idx:0, frame:b64 })
      });
      const d = await r.json();
      if (d.frame) depthImg.src="data:image/jpeg;base64,"+d.frame;
    } catch(e){ console.error(e) }
  }
  
  async function processImageDepth(){
    try {
      const b64 = await captureSideFrame();
      const r = await fetch("/process_depth",{
        method:"POST",
        headers:{"Content-Type":"application/json"},
        body:JSON.stringify({ camera_mode:"image_depth", local_idx:0, frame:b64 })
      });
      const d = await r.json();
      if (d.frame) depthImg.src="data:image/jpeg;base64,"+d.frame;
    } catch(e){ console.error(e) }
  }
  
  /****************************************************
   * FRAME CAPTURE UTILS
   ****************************************************/
  function captureSideFrame(){
    return new Promise((res,rej)=>{
      if (sideCamModeSelect.value==="camera" && localStream){
        const c=document.createElement("canvas");
        c.width=sideVideo.videoWidth; c.height=sideVideo.videoHeight;
        c.getContext("2d").drawImage(sideVideo,0,0);
        res(c.toDataURL("image/jpeg").split(",")[1]);
      } else if (uploadedImageData){
        const p=uploadedImageData.split(",");
        p[1]? res(p[1]) : rej("Bad dataURL");
      } else rej("No frame");
    });
  }
  function captureSegFrame(){
    return new Promise((res,rej)=>{
      if (segMode.value==="realsense_seg"){
        const p=segImg.src.split(",");
        p[1]? res(p[1]) : rej("No RealSense frame");
      }
      else if (segMode.value==="seg"){
        if (sideCamModeSelect.value==="camera"&&localStream){
          const c=document.createElement("canvas");
          c.width=segVideo.videoWidth; c.height=segVideo.videoHeight;
          c.getContext("2d").drawImage(segVideo,0,0);
          res(c.toDataURL("image/jpeg").split(",")[1]);
        } else {
          const p=uploadedImageData.split(",");
          p[1]? res(p[1]) : rej("No uploaded image");
        }
      } else rej("Unsupported mode");
    });
  }
  
  /****************************************************
   * CHAT (Window4)
   ****************************************************/
  function addChatMessage(sender,msg){
    if (chatMessages.children.length>1000) chatMessages.removeChild(chatMessages.firstChild);
    const dv=document.createElement("div");
    dv.innerHTML=`<strong>${sender}:</strong> ${msg}`;
    chatMessages.appendChild(dv);
    chatMessages.scrollTop = chatMessages.scrollHeight;
  }
  
/****************************************************
 * CHAT (Window4)  — send a line to the back-end
 ****************************************************/
 async function sendChat(customText){
  const txt       = (customText || chatInput.value).trim();
  if (!txt) return;

  chatInput.value = "";
  addChatMessage("You", txt);

  //-------------------------------------------------
  // Freeze the current Seg frame (if not already)
  //-------------------------------------------------
  let frameB64 = "";
  try {
    frameB64   = await captureSegFrame();
    segFrozen  = true;
    clearInterval(realsenseSegTimer);
    if (segMode.value === "seg" && localStream) {
      segVideo.pause();
      segVideo.srcObject = null;
    }
    segImg.src            = "data:image/jpeg;base64," + frameB64;
    segImg.style.display  = "block";
    segVideo.style.display= "none";
  } catch {}

  //-------------------------------------------------
  // Tell the user what we’re about to do
  //-------------------------------------------------
  const txtLower = txt.toLowerCase();
  if (txtLower === "yes" || txtLower === "y"){
    addChatMessage("AAU Agent", "Confirming your selection…");
  } else {
    addChatMessage(
      "AAU Agent",
      "Sending request to AI server, this may take a few seconds…"
    );
  }

  //-------------------------------------------------
  // Call the Flask back-end
  //-------------------------------------------------
  let d = null;
  try {
    const resp = await fetch("/chat", {
      method : "POST",
      headers: { "Content-Type":"application/json" },
      body   : JSON.stringify({
        text      : txt,
        seg_input : segMode.value,
        seg_frame : frameB64
      })
    });

    if (!resp.ok){
      // server returned 4xx/5xx → show first 120 chars of plain text
      const errText = (await resp.text()).slice(0,120);
      addChatMessage("AAU Agent", `Server error (${resp.status}): ${errText}`);
      return;
    }
    d = await resp.json();
  }
  catch(e){
    console.error(e);
    addChatMessage("AAU Agent", "Error: " + e);
    return;
  }

  //-------------------------------------------------
  // Show overlay frame (candidate OR final segment)
  //-------------------------------------------------
  const ov = d.overlay_frame || d.seg_frame;
  if (ov) {
    // Just update directly—no blanking + timeout
    segImg.src = "data:image/jpeg;base64," + ov;
  }


  //-------------------------------------------------
  // Show geometry if present
  //-------------------------------------------------
  if (d.object_info){
    addChatMessage(
      "AAU Agent",
      `Center: ${d.object_info.center_xyz_m.map(v=>v.toFixed(3)).join(', ')} m, `
    + `distance ${d.object_info.distance_m.toFixed(3)} m, `
    + `W×H ${(d.object_info.width_m*100).toFixed(1)}×${(d.object_info.height_m*100).toFixed(1)} cm`
    );
  }

  //-------------------------------------------------
  // Always show the first line of the textual reply
  //-------------------------------------------------
  addChatMessage("AAU Agent", d.reply.split("\n")[0]);

  //-------------------------------------------------
  // If we’re still in confirm stage, prompt the user
  //-------------------------------------------------
  if (d.overlay_frame && !d.seg_frame){
    setTimeout(()=> addChatMessage(
      "AAU Agent",
      "Selecting best candidate point (in blue). Please type “yes” if the point is on the correct object."
    ), 800);
  }
}

  chatSendBtn.addEventListener("click",()=>sendChat());
  chatInput.addEventListener("keyup",e=>{ if(e.key==="Enter") sendChat(); });
  
  /****************************************************
   * LLM Console
   ****************************************************/
  function logToConsole(msg){
    if (llmConsole.children.length>1000) llmConsole.removeChild(llmConsole.firstChild);
    const dv=document.createElement("div");
    dv.textContent=msg;
    llmConsole.appendChild(dv);
    llmConsole.scrollTop=llmConsole.scrollHeight;
  }
  </script>
  